# Hadoop分布式文件系统

## 前言
当我们的数据集的大小超过了单机容量的极限时，就需要把数据拆分并存储在不同的机器上。
而管理跨机器之间数据存储的文件系统就被称为分布式文件系统(Distributed Filesystem)。
HDFS(Hadoop Distribute Filesystem)正是Hadoop的旗舰型文件管理系统，它是Hadoop框架的核心组件之一，主要用于实现分布式文件管理。

## HDFS概要
HDFS设计的初衷是：在廉价的商用集群上，通过流数据访问的方式实现超大文件的存储。有是三个突出特点：
1. 超大文件：文件在G，百G甚至是百T级别。
2. 流数据访问:HDFS是基于一次写入，多次读取这种最高效的数据处理模式（流数据模式）创建的。
3. 廉价的商业集群：Hadoop并不要求价格高昂、高稳定的机器。即使在廉价的、故障率较高的廉价集群上，hadoop也能很好得完成工作。Hadoop有完善的机制处理异常问题。

然而，在带来这些便利的同时，HDFS的一些特性也使得它无法满足以下的应用场景：
1. 低延迟数据访问：HDFS是基于高数据通量，而不是高通率的理念设计的，高延迟是无法避免。Hbase是低延迟的要求的更佳选择。
2. 数据是大量小文件：由于文件系统的元数据都是存储在内存中的名称节点（namenode）上，因此可管理文件的数量就受限于内存大大小。
3. 数据有多个写入者，并需要任意次修改：HDFS目前之支持单方，附加式的写入。
## HDFS基本概念
### 块（Blocks）
数据存储的磁盘是由无数的数据块组成的。块大小指的是最小可读取的数据量。基于磁盘的文件系统（比如Windows操作系统）同样也使用块来管理数据，
只不过文件系统的节点通常是由多个磁盘节点组成的。一般文件系统的块是几个KB，而磁盘数据块通常是512B。这样的块大小已经可以满足一般用户对于任意大小文件的读写。
当然，有些操作系统还支持块级的操作，比如Linux中的df和fsck命令。
